{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection Data\n",
    "\n",
    "**Offer a strategy and write code to either generate or collect enough samples for us to be\n",
    "able to train a model extracting the recipient.**\n",
    "\n",
    "I downloaded movie lines from [here](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)\n",
    "I created a conversation database and a name database. I also created a list of wake words, such as \"tell\" and \"message\". Then I randomly combine a wake word, a name, and one or two messages. See function command_gen() for detail.\n",
    "\n",
    "**How many samples do you think we need? Why?**\n",
    "\n",
    "Since the format/sentence structure doesn't have too many variation. I don't think we need a large amount of samples like general object recognition. 10-100 thousands sample should be enough.\n",
    "\n",
    "**What limitations do you see to your approach?**\n",
    "The wake word list might be limited. People might be use different words to ask the program to send messages. Samples often assume people have said perfect sentences. In reality, people might say something like \"please send...ummm...Jack...wait no...John...a message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Message and Contact Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Lines and Names and Create a Contact Database and a Message Database\n",
    "file = open(\"./cornell_movie-dialogs_corpus/movie_lines.txt\", \"rb\") \n",
    "#file = open(\"./sample.txt\", \"rb\")\n",
    "contacts, messages = [], []\n",
    "for line in file:\n",
    "    line = line.decode('utf-8', errors='ignore').strip('\\n')\n",
    "    split_line = line.split(\"+++$+++\")\n",
    "    recipent = split_line[3].strip()\n",
    "    sentences = nltk.sent_tokenize(split_line[-1].strip())\n",
    "    #print(split_line)\n",
    "    if len(recipent) < 1:\n",
    "        continue\n",
    "    else:\n",
    "        contacts.append(recipent[0]+recipent[1:].lower())\n",
    "    messages.extend(sentences)\n",
    "\n",
    "# Remove Duplicate Contacts and Shuffle Messages\n",
    "contacts = list(set(contacts))\n",
    "random.shuffle(messages)\n",
    "\n",
    "# Remove Names with Errors\n",
    "new_contacts = []\n",
    "for contact in contacts:\n",
    "    if '\\t\\t\\t' in contact:\n",
    "        continue\n",
    "    if ']' in contact:\n",
    "        continue\n",
    "    new_contacts.append(' '.join(contact.split()))\n",
    "contacts = new_contacts    \n",
    "\n",
    "# Create Contact Dict For Easy Lookup\n",
    "contacts_dict = defaultdict(list)\n",
    "for contact in contacts:\n",
    "    contact_split = contact.split()\n",
    "    contacts_dict[contact_split[0].lower()].append(contact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_words = ['tell',\n",
    "              'notify',\n",
    "              'ask',\n",
    "              'inform',\n",
    "              'message',\n",
    "              'text',\n",
    "              'reply to',\n",
    "              'mention to',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_gen(wake_words, messages, contacts):\n",
    "    num_messages = len(messages)\n",
    "    i = 0\n",
    "    dataset = []\n",
    "    recipents = []\n",
    "\n",
    "    while i < num_messages:\n",
    "        # Wake words\n",
    "        wake_word = random.sample(wake_words, 1)[0]\n",
    "        if random.random() < 0.5:\n",
    "            command = \"Can you \"\\\n",
    "                      + wake_word\\\n",
    "                      + \" \"              \n",
    "        else:\n",
    "            command = wake_word[0].upper()\\\n",
    "                      + wake_word[1:]\\\n",
    "                      + \" \"\n",
    "\n",
    "        # Recipent\n",
    "        contact = random.sample(contacts, 1)[0]\n",
    "        command += contact\n",
    "        recipents.append(contact)\n",
    "\n",
    "        # Message(s)\n",
    "        if random.random() < 0.5:\n",
    "            command += ' that'\n",
    "\n",
    "        command += \" \" + messages[i]\n",
    "        i += 1\n",
    "\n",
    "        if random.random() < 0.25 and i < num_messages:\n",
    "            command += \" and that \"\\\n",
    "                       + messages[i]\n",
    "            i += 1\n",
    "\n",
    "        dataset.append(command)\n",
    "        \n",
    "    return dataset, recipents\n",
    "\n",
    "dataset, recipents = command_gen(wake_words, messages, contacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(dataset, open('command_dataset.pickle', 'wb'))\n",
    "#pickle.dump(recipents, open('recipents_dataset.pickle', 'wb'))\n",
    "\n",
    "#dataset = pickle.load(open('command_dataset.pickle', 'rb'))\n",
    "#recipents = pickle.load(open('recipents_dataset.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model\n",
    "\n",
    "**Discuss what the advantages and limitations of all these different approaches are.**\n",
    "I chose two approaches, one is rule based and the other is logistic regression.\n",
    "Rule based doesn't require many samples. But it could be high computational complexity. Because it searches a contact name thru the sentence. The complexity would be N x M. N is the number of words in the command, and M is the number of contacts a user has. The rule based approaches is implemented in funciton find_recipent_rule_base().\n",
    "\n",
    "The second approach is a machine learning approach. I did a word tokenization, and turned each word into a data point. They are labeled as whether they are (or part of) a recipent or not. Advantatge is that it is robust to different sentence format. Also rather saying \"Recipent not found in your contact list\", it could say for example \"John not found in your contact list\". Limitations will be that it requires more data to achieve a certain level of accuracy.\n",
    "\n",
    "**How did you select your features? Did you engineer new ones? Please describe in detail the entire process, including how you chose the training/validation/testing data split, how you did your hyper-parameter tuning, etc.**\n",
    "For the logistic regression. I extracted the word before and the word after the data point. I also used the location in the sentence as a feature. My orgininal thought is to split the data into 80% training and 20% testing. Then within the 80% training, I would use cross-validation to tune the hyper-parameters. However at the end, the data is too large for my computer to handle. So I took 50000 data points from training set and 5000 data points from testing set. I still did a cross validation using the 50000 training data points and tuned the regularization of the logistic regression. Finally using the 5000 testing data points to evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, recipents, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recipent_rule_based(command):\n",
    "    \n",
    "    wake_word_said = False\n",
    "    words = command.split()\n",
    "    i = 0\n",
    "    \n",
    "    # only searching for recipent if wake word is said\n",
    "    while i < len(words):\n",
    "        if words[i].lower() in wake_words:\n",
    "            i += 1\n",
    "            wake_word_said = True\n",
    "            break\n",
    "        elif ' '.join(words[i:i+2]).lower() in wake_words:\n",
    "            i += 2\n",
    "            wake_word_said = True\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    # rearching for first word of recipent name\n",
    "    if wake_word_said:\n",
    "        while words[i].lower() not in contacts_dict and i < len(words):\n",
    "            i += 1\n",
    "            \n",
    "    # when found, find the whole recipent name\n",
    "    if i < len(words):\n",
    "        if words[i].lower() in contacts_dict:\n",
    "            sub_sentence = ' '.join(words[i:])\n",
    "            max_matching_len = 0\n",
    "\n",
    "            for name in contacts_dict[words[i].lower()]:\n",
    "                if name in sub_sentence and len(name)>max_matching_len:\n",
    "                    max_matching_len = len(name)\n",
    "                    recipent = name\n",
    "            try:\n",
    "                return recipent\n",
    "            except:\n",
    "                print(contacts_dict[words[i].lower()])\n",
    "\n",
    "        i += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rb = []\n",
    "for test in X_test:\n",
    "    y_pred_rb.append(find_recipent_rule_based(test))\n",
    "\n",
    "correct = 0\n",
    "for y, y_bar in zip(y_test, y_pred_rb):\n",
    "    correct += int(y==y_bar)\n",
    "    if y != y_bar:\n",
    "        print(y, y_bar)\n",
    "\n",
    "rb_accuracy = correct/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach - Logistic Regression\n",
    "\n",
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_label(command, label, n):\n",
    "\n",
    "    words = nltk.word_tokenize(command)\n",
    "    words=[word.lower() for word in words if word.isalpha()]\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    num_words = len(words)\n",
    "    for i, word in enumerate(words):\n",
    "        feature = []\n",
    "        for j in range(n, 0, -1):\n",
    "            k = i-j\n",
    "            if k >= 0:\n",
    "                feature.append(words[k])\n",
    "            else:\n",
    "                feature.append('NA')\n",
    "        for j in range(1, n+1):\n",
    "            k = i+j\n",
    "            if k < num_words:\n",
    "                feature.append(words[k])\n",
    "            else:\n",
    "                feature.append('NA')\n",
    "        feature.append(i)\n",
    "        features.append(feature)\n",
    "\n",
    "        if word in label.lower().split():\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    return features, labels\n",
    "\n",
    "def sentence_to_words(X, y, n_neighbor=1, balanced=True):\n",
    "\n",
    "    X_word_token, y_word_token = [], []\n",
    "    for command, recipent in zip(X, y):\n",
    "        features, labels = extract_feature_label(command, recipent, n_neighbor)\n",
    "        X_word_token += features\n",
    "        y_word_token += labels\n",
    "\n",
    "    if balanced:\n",
    "        ratio = sum(y_word_token)/len(y_word_token)\n",
    "\n",
    "        X_word_token_blc, y_word_token_blc = [], []\n",
    "        for feature, label in zip(X_word_token, y_word_token):\n",
    "            if label == 0 and random.random() > ratio:\n",
    "                continue\n",
    "            X_word_token_blc.append(feature)\n",
    "            y_word_token_blc.append(label)\n",
    "        \n",
    "        X_word_token = X_word_token_blc\n",
    "        y_word_token = y_word_token_blc\n",
    "    dataset = np.concatenate((np.array(X_word_token), \n",
    "                              np.array(y_word_token).reshape(-1,1)), \n",
    "                              axis=1)\n",
    "\n",
    "\n",
    "    fwd, back = [], []\n",
    "    for i in range(n_neighbor):\n",
    "        fwd.append('-'+str(i+1)+'_loc')\n",
    "        back.append('+'+str(i+1)+'_loc')\n",
    "    fwd.reverse()\n",
    "    col_names = fwd+back+['loc','label']\n",
    "    \n",
    "    return pd.DataFrame(dataset, columns=col_names)\n",
    "\n",
    "df = sentence_to_words(dataset, recipents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(df, open('df.pickle', 'wb'))\n",
    "#df = pickle.load(open('df.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a sample due to large size of original dataset\n",
    "train_df, test_df = train_test_split(df)\n",
    "sample_train_df = train_df.sample(50000)\n",
    "sample_test_df = test_df.sample(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer - Extract Numerical Values from Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ENGLISH_STOP_WORDS.union('NA')\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]    \n",
    "\n",
    "CV_fwd = CountVectorizer(stop_words=stop_words, tokenizer=LemmaTokenizer())\n",
    "CV_bck = CountVectorizer(stop_words=stop_words, tokenizer=LemmaTokenizer())\n",
    "CV_fwd.fit(sample_train_df['-1_loc'])\n",
    "CV_bck.fit(sample_train_df['+1_loc'])\n",
    "    \n",
    "def extract_feature(df):\n",
    "    X_fwd = CV_fwd.transform(df['-1_loc'])\n",
    "    X_bck = CV_bck.transform(df['+1_loc'])\n",
    "\n",
    "    loc = np.array(df['loc'].tolist()).reshape(-1,1).astype(int)\n",
    "    X = np.concatenate((X_fwd.toarray(), X_bck.toarray(), loc), axis=1)\n",
    "\n",
    "    y = np.array(df['label'].tolist()).astype(int)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = extract_feature(sample_train_df)\n",
    "X_test, y_test = extract_feature(sample_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (With GridSearchCV to Tune Hyper-Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C':[0.1, 1, 10], 'penalty':['l1','l2']}\n",
    "LR = LogisticRegression()\n",
    "clf = GridSearchCV(LR, parameters, cv=5, n_jobs=-1, verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "LR = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation \n",
    "\n",
    "**What is the accuracy for each one of your models? How much data did you use to evaluate your model? Is it better/worse than you expected? Is the model overfitting? If so, how do you ‘fix’ it? **\n",
    "\n",
    "Rule based achieved 100%, but I wouldn't expect rule based approach did very good in the real world scenarios. I created those sample data therefore I know very well how to find the recipents. It is almost like cheating.\n",
    "The Logistic Regression achieved a 92.43% on the testing sample data. It is actually better than I expected since I only used one word before and one word after the word I am classifying. However, again, the data I generated might not be representative enough. More brainstorming of how to collect/generate data is needed.\n",
    "\n",
    "**Then think of other metrics you’d like to look at to evaluate the ‘goodness’ of your model. Why do you think these metrics are important?**\n",
    "Computational complexity is an important metrics since customers wouldn't like to wait forever to send a message.\n",
    "\n",
    "## Rule Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Sophisticated Model\n",
    "\n",
    "I didn't have enough time to finish this. I did look into (Stanford's CRF-NER)[https://nlp.stanford.edu/software/CRF-NER.shtml] but I didn't have the expertise to complete a sophisticated model in a week. I also thought of using Spacy to identify part-of-speech of each token. Instead extract the word before and after the one we're trying to classify (like I did for the logistic regression), we can extract the POS instead. This approach could be more robust and reduce feature dimenstion by a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can VERB MD\n",
      "you PRON PRP\n",
      "reply VERB VB\n",
      "to ADP IN\n",
      "Tricks NOUN NNS\n",
      "that ADJ WDT\n",
      "Come VERB VBP\n",
      "here ADV RB\n",
      ", PUNCT ,\n",
      "Brenna PROPN NNP\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(dataset[5])\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
